---
title: "Week 2: Introduction II"
---

# Handling Data Structures in RStudio

## Learning objectives

By the end of this tutorial, you will be able to:

1. Set your working directory on Mac and Windows
2. Import a .csv file into RStudio
3. Understand the structure of a data frame (rows and columns)
4. Filter data using both numeric and categorical variables
5. Combine multiple conditions with logical operators to perform further filtering of data
6. Export data back into a .csv file

These objectives, combined with those from last week, serve as a gateway to learning RStudio and building a strong foundation. Let us begin!

## Setting the Working Directory to Datasets (Length: 00:05:24)

```{r, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('-rzneFvp190', height=400, allowfullscreen = TRUE) %>% use_align('center')
```
[[**Watch on YouTube**]](https://youtu.be/-rzneFvp190)

:::{.callout-warning}
Before we do anything - make sure to have downloaded the dataset for this computer session by clicking [**[HERE]**](https://github.com/UCLPG-MSC-SGDS/GEOG0186/raw/main/datasets/Dataset%20for%20Week%202.zip). It contains the file `Primary Schools in Ealing.csv` - this comma separated values (CSV) file contains the data needed to follow today's tutorial.

**Instructions**
In your computer, do the following:

1. Create a new folder on your desktop and rename the folder **GEOG0186**
2. Next, create a new sub-folder within **GEOG0186** and rename it as **Week 2**.
3. From the downloaded folder **Dataset for Week 2**, make sure to unzip and transfer **ALL** the datasets directly to the **Week 2** folder.
:::

This part is probably the most important section of this tutorial. We are going to learn how to set the **Work Directory**. This basically refers to us connecting the RStudio to the folder containing our dataset that we want to import and analyse. 

Doing this allows the user to tell RStudio to open data from a folder located somewhere in our computer using something called the **Path Location**. 

The **Path Location** specifies the whereabouts of the data file(s) stored within a computer. Setting your directory in RStudio, **in code**, beforehand makes life incredibly easier (than the usual point-and-click approach) in terms of finding, importing, exporting and saving data in and out of RStudio.

To illustrate what a **Path Location** is – suppose on my desktop's dashboard on a Mac/Windows there is a folder called **GEOG0186**, and within that folder, exists another folder called **Week 2**. Finally, suppose a comma separated value (.csv) data file called `Primary Schools in Ealing.csv` is store in this folder i.e., **Week 2**. If via RStudio you want to open this CSV data file located in within the **Week 2** folder. You will need to first set the path to **Week 2** in RStudio using the `setwd()` function.

### Setting the Path Location on MAC (Length: 00:06:44)

```{r, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('S0CaXUH0Mz0', height=400, allowfullscreen = TRUE) %>% use_align('center')
```
[[**Watch on YouTube**]](https://youtu.be/S0CaXUH0Mz0)

For **MAC** users, the path location would be written as follows, `"/Users/accountName/Desktop/GEOG0186/Week 2"`. You can access this piece of information simply by:

1. Open the folder **GEOG0186**
2. Right-clicking on the folder **Week 2** in which the files are stored. A drop-down scroll menu will appear (see image below).

```{r echo=FALSE, out.width = "100%", fig.align='center', cache=TRUE,}
knitr::include_graphics('assets/all_images/set_working_directory/00_setwd_mac.png', error = FALSE) 
```

3. Hold the **Option** (`⌥`) button on your keyboard down, and click **Copy "Week 2" as Pathname**
4. Paste the copied path name into the function `setwd()` and run the code

For Mac, the `setwd()` is as follows:

```{r, eval=FALSE}
# set work directory in macs
setwd("/Users/accountName/Desktop/GEOG0186/Week 2")
```

### Setting the Path Location on Windows (Length: 00:05:07)

```{r, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('_r0MTEnoOhg', height=400, allowfullscreen = TRUE) %>% use_align('center')
```
[[**Watch on YouTube**]](https://youtu.be/_r0MTEnoOhg)

For Windows user (on **UCL PCs**), its marginally different - the path location to this folder on a **Windows** machine would be written as follows, `"N:/Desktop/GEOG00186/Week 2"`. You can access this piece of information simply by:

1. Open the **GEOG0186** folder to reveal the **Week 2** folder.
2. Open the **Week 2** folder where your downloaded data files have been stored.
3. Now, click on the browser bar at the top which shows `GEOG0186 > Week 2`. This should highlight and show `"N:\Desktop\GEOG0186\Week 2"` (see image below).

```{r echo=FALSE, out.width = "100%", fig.align='center', cache=TRUE,}
knitr::include_graphics('assets/all_images/set_working_directory/01_setwd_windows.png', error = FALSE) 
```

4. Now, copy `"N:\Desktop\GEOG0186\Week 2"` and paste the path name into the `setwd()` function in your R script.
5. Lastly, change all the back slashes `\` in the path name to forward slashes `/` and run the code. It should look like this: `setwd("N:/Desktop/GEOG0186/Week 2")`.

For **Windows**, the `setwd()` is as follows:

```{r, eval=FALSE}
# set work directory in windows (using UCL PC)
setwd("N:/Desktop/GEOG0186/Week 2")

# note that on usual Windows OS on a personal computer - the code looks something like:
setwd("C:/Users/accountName/Desktop/GEOG0186/Week 2")
```

If you type the code `getwd()` and quickly run it through console - if it returns the inputted path location - then you have done this correctly.

Now, let us learn how to import a CSV data into RStudio.

## How to Import a Dataset into RStudio (Length: 00:06:21)

```{r, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('MxBlUJkKOnA', height=400, allowfullscreen = TRUE) %>% use_align('center')
```
[[**Watch on YouTube**]](https://youtu.be/MxBlUJkKOnA)

A CSV file (short for Comma-Separated Values) is one of the most common formats for storing data.
Each **row** is a **single record** or **observation**. For example, it can be details about a person, household unit, a city, or even disease events; and while each **column** is a **variable** (for example, population counts, temperature readings, or region name etc.).

For this exercise, we will be using the `Primary Schools in Ealing.csv` dataset to build intuition on understanding the basics of data structure.

Since, we have already set the work directory to folder containing this dataset. Importing it into RStudio would be a piece of cake.

To read a CSV file into R, we can use the `read.csv()` function import it as a **data frame object** named `school_data` using the assignment operator (`<-`):

```{r setup, include = FALSE}
knitr::opts_knit$set(root.dir = "/Users/anwarmusah/Documents/Websites/GEOG0186/datasets/All Data")
knitr::opts_chunk$set(cache = TRUE)
```

```{r}
# Load data into RStudio. The spreadsheet is stored in the object called 'school_data'
school_data <- read.csv(file = "Primary Schools in Ealing.csv")
```

The loaded dataset contains up to 58 primary schools with the following **variables**:

- `SchoolName`: Name of school in Ealing (**character**)
- `Type`: School classified as a "Primary" school (**character**)
- `NumberBoys`: Total number of boys in a primary school (**integer**/)
- `NumberGirls`: Total number of girls in a primary school (**integer**)
- `TotalStudents`: Total number of students in a primary school (**integer**)
- `OfstedGrade`: Overall school performance where `1` = "excellent", `2` = "good", `3` = "requires improvement", and `4` = "inadequate" (**factor**/**categorical**)

:::{.callout-important}
We have covered a lot of the basics in RStudio - i.e., setting the work directory and importing a spreadsheet that is CSV format. The things shown in this section will be used frequently in all future tutorials. So, get used to using `setwd()` and `read.csv()`.
:::

## Data Structure

### Inspecting the Size and Structure (Length: 00:08:16)

```{r, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('PDEw6dIlijg', height=400, allowfullscreen = TRUE) %>% use_align('center')
```
[[**Watch on YouTube**]](https://youtu.be/PDEw6dIlijg)

One can examine the structure of the imported data with the following basic functions.

- `str()`: tells the user which columns in the data frame are character or numeric variables, and so on.
- `names()`: prints the entire names of the columns present in the data frame
- `head()`: allows the user to see the first top 10 rows of the data frame
- `tail()`: allows the user to see the last bottom 10 rows of the data frame
- `ncol()`: tells the user the total number of columns present in the data frame
- `nrow()`: tells the user the total number of observations (or rows) present in the data frame
- `dim()`: prints both the total number of observations (or rows) and columns present in the data frame.

Using the following code `str()` will display the structure of `school_data` data frame object and some of its contents:

```{r}
str(school_data)
```

Using the following code `head()` or `tail()` will display the first or last 10 observations, respectively, in the `school_data` data frame object:

```{r, max.height='100px'}
head(school_data)
tail(school_data)
```

You can inspect the data frame object in a **Data viewer** by using the `View()` syntax. This should cause the **Data viewer** window to open showing the full dataset:

```{r, eval=FALSE}
View(school_data)
```

The dataset has 58 rows (primary school observations) and 6 columns (variables). You can use `nrow`, `ncol` and `dim()` functions separately to report the size of your data frame: 

```{r}
# total number of rows
nrow(school_data)

# total number of columns
ncol(school_data)

# full size of data frame i.e., total rows and columns
dim(school_data)
```

### Basic Manipulation of Data Frame

#### Subsetting using Rows and Columns (Length: 00:17:06)

```{r, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('dE9Jc9_hCQA', height=400, allowfullscreen = TRUE) %>% use_align('center')
```
[[**Watch on YouTube**]](https://youtu.be/dE9Jc9_hCQA)

One can subset or restrict the data frame by specifying which row(s) and column(s) to keep or discard using this standard square bracket syntax `dataframe[Row, Column]`.

Breakdown of `dataframe[Row, Column]`code:

1. The bit in the code that corresponds to `dataframe` from `dataframe[Row, Column]` represents the **name** data frame object.
2. Where it states `Row` within the square brackets specifies the subsetting, or filter action to be carried out based on rows.
3. Where it states `Column` within the square brackets specifies the subsetting, or filter action to be carried out based on columns.

Let's take our `school_data` data frame as an example - if we select the first row (row number 1) and the first column (SchoolName), we have essentially filter out only the school name `Berrymede Junior School Primary`:

```{r}
data11 <- school_data[1, 1]
data11
```

If you select only the first row (row number 1) and do not specific any numbers for the columns, you will be filtering out the entire row for row number 1:

```{r}
row1 <- school_data[1, ]
row1
```

In the same vein, if you select only the column and do not specific any numbers for the rows, you will be filtering out the entire column (i.e., `SchoolName` variable) for column number 1 which is the list of all primary school names:

```{r}
column1 <- school_data[, 1]
column1
```

What if we wanted to filter the following rows numbered `2`, `7` and `19` from the `school_data` data frame object as highlighted in the image below?

```{r echo=FALSE, out.width = "100%", fig.align='center', cache=TRUE,}
knitr::include_graphics('assets/all_images/subsetting_dfs/01_rows_only.png', error = FALSE) 
```

We can use the combine function i.e., `c()` to list those numbers in the square brackets:

```{r}
rows_filter <- school_data[c(2, 7, 19), ]
rows_filter
```

Likewise, what if we wanted to filter the following columns numbered `1`, `5` and `6` from the `school_data` data frame object as highlighted in the image below?

```{r echo=FALSE, out.width = "100%", fig.align='center', cache=TRUE,}
knitr::include_graphics('assets/all_images/subsetting_dfs/02_columns_only.png', error = FALSE) 
```

We can also use the combine function i.e., `c()` to list those numbers for the columns within that square brackets:

```{r}
columns_filter <- school_data[ , c(1, 5, 6)]
columns_filter
```

What if we wanted to filter on rows numbered `2`, `7` and `19`, as well as columns numbered `1`, `5` and `6` from that `school_data` data frame object as highlighted in the image below?

```{r echo=FALSE, out.width = "100%", fig.align='center', cache=TRUE,}
knitr::include_graphics('assets/all_images/subsetting_dfs/03_rows_and_columns.png', error = FALSE) 
```

```{r}
full_filter <- school_data[c(2, 7, 19) , c(1, 5, 6)]
full_filter
```

Not too shabby! So far, you have been shown how to do some create subset of data by filtering rows and columns. Let's take it up a notch on filtering based on row **Logical Operators** to create **conditions**.

#### Subsetting using Logical Operators to Combine Conditions (Length: 00:15:38)

```{r, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('I3dpW72kqVQ', height=400, allowfullscreen = TRUE) %>% use_align('center')
```
[[**Watch on YouTube**]](https://youtu.be/I3dpW72kqVQ)

Often, we want to filter based on more than one condition — for example, "cities in England **and** with a population over 600000". RStudio uses logical operators to combine these conditions:

| Operator | Meaning | Example | Description |
|:---|:---------|:-----------------------|:------------------------------|
|`==`| Equal to | `country == "England"` | True if the country is England|
|`!=`| Not Equal to | `country != "England"` | True if for all except England|
|`>`|Greater than | `population > 600000` | True if population is above 600000|
|`<`|Less than | `population < 600000` | True if population is under 600000|
|`>=`|Greater than or eqaul to | `population >= 600000` | True if population is equal to 600000 or more|
|`<=`|Less than or equal to | `population <= 600000` | True if population is equal to 600000 or less|
|`&`|AND | `country == "England" & population <= 600000` | Both conditions are true |
|`|`|OR | `country == "England" | country == "Wales"` | True for either England or Wales |

Let's illustrate with the `school_data` object. We are interested in primary schools with a total of 500 hundred or more students. This operation is **always** row-based. We will need to use the `$` to call the column `TotalStudents` and the logical operator for this filter is `>=`: 

```{r}
schools_500plus <- school_data[school_data$TotalStudents >= 500, ]
schools_500plus
```

What if were interested in primary schools with an OFSTED score of `1` (Excellent). Again, this operation is row-based and so we will need to use the `$` to call the column `OfstedGrade` and the logical operator for this filter is `==`:

```{r}
schools_ofsted1 <- school_data[school_data$OfstedGrade == 1, ]
schools_ofsted1
```

Here is an example of combining such logical operators - select schools that have more than 650 students and with an OFSTED score of 2.

```{r}
# logical operators is >, &, ==
schools_650_ofsted2 <- school_data[school_data$TotalStudents > 650 & school_data$OfstedGrade == 2, ]
schools_650_ofsted2
```

I am sure you now get the gist of what is happening here with these logical statements for subsetting, or filtering data accordingly. We are now in the final stretch - let us learn how to save and export a dataset as a CSV spreadsheet.

## Saving your dataset (Length: 00:11:13)

```{r, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('Ssiawr3ADnw', height=400, allowfullscreen = TRUE) %>% use_align('center')
```
[[**Watch on YouTube**]](https://youtu.be/Ssiawr3ADnw)

This operation is very easy to perform. Once you have created your filtered data, you can use the following function `write.csv()` to save it as a new CSV file:

```{r, eval=FALSE}
write.csv(schools_650_ofsted2, file = "Filtered_example_data.csv", row.names = FALSE)
```

The above syntax should save a new CSV file named as `Filtered_example_data.csv`. Do not forget to save your R-script!

## Summary

You have learned the following:

1. Set your working directory on Mac and Windows
2. Import a .csv file into RStudio
3. Understand the structure of a data frame (rows and columns)
4. Filter data using both numeric and categorical variables
5. Combine multiple conditions with logical operators to perform further filtering of data
6. Export data back into a .csv file

# Worksheet One: Workflow and Generating Data in RStudio

In this worksheet, we will put into practice some of the basics we learned in Introduction I and II. The aim of this worksheet is to transcribe the image data containing stormwater drain infrastructure and sanitation information using the following R code syntax:

- Assignment operator `<-`
- Combine function `c()`
- Data frame function `data.frame()`
- Display data structure of output `str()`
- Using logical operators
- Save function `write.csv()`

**Scenario: Stormwater Drainage Survey Data**

In Accra, between June and July 2024, we conducted a stormwater drainage survey to identify exposed drainage points along street segments that were clogged with solid waste (e.g., plastics and rubbish) and stagnant water, with the aim of reducing the burden of poor environmental sanitation and the risk of mosquito-borne infestation.

Following information has been captured in annotated images:

```{r echo=FALSE, out.width = "100%", fig.align='center', cache=TRUE,}
knitr::include_graphics('assets/all_images/tasks/00_drain_exhibits.png', error = FALSE) 
```

Use the information in the white text box of each image to construct a data frame in RStudio.

1. Use the `c( )` function with assignment operator (`<-`) to create the following vector objects with the names:

- `GoProID`: it contains the image ID numbers
-	`Latitude`: it contains the y-coordinate of surveyed location
-	`Longitude`: it contains the x-coordinate of surveyed location
-	`Sanitation`: it contains information about the sanitation state of drain
-	`SolidWaste`: it describes presence or absence of solid waste materials in drain
-	`Structure`: it describes whether the structure of the drain was damaged (or not) or it being a “run off” drain
-	`Stagnation`:  refers to flow obstruction in drain resulting in it be stagnated
-	`Mosquitoes`: refers to evidence of mosquito breeding in drain due to condition

2. Use the `data.frame()` with the assignment operator (`<-`) to create the data frame object `drainage_data`.
3. Use the `str()` to describe the structure of `drainage_data` data frame.
4. Use the following row conditions i.e., drains classified as having **Poor** sanitary state **AND** it is a **Breeding Spot** for mosquitoes at the same time to perform a filter on the `drainage_data` object. At the same time, limit the filtered data to the following columns: `GoProID`, `Latitude`, `Longitude`, `Sanitation` and `Mosquitoes`   
5. Use the `write.csv()` to save your new filtered dataset.

:::{.callout-important}
Please use the answer sheet [**HERE**](https://github.com/UCLPG-MSC-SGDS/GEOG0186/raw/main/tasks/Answers%20sheet%20for%20task%201.docx) to insert a screenshot of the dataset, paste the full code syntax, and provide an interpretation of the dataset and workflow. Note that this **Worksheet 1**, in particular, along with **Worksheets 2 and 3**, will only be assessed in person, and feedback will also be given in person. Whereas **Worksheets 4 and 5 - London Air Quality** - will be formatively marked accordingly. You need to submit at least 2 (out of 5) QSkills worksheets in your final portfolio.
:::