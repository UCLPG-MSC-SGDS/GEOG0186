---
title: "Week 3: Examining Data I"
---

# Frequency Distribution

## Learning outcomes

By the end of this tutorial, you will be able to:

1. Understand frequency distributions
2. How to categorise continuous measurements in classes/categorise using the `cut()`
3. How to compute a frequency table
4. How to provide an interpretation to such outputs
5. How to translate a frequency distribution table into a histogram and cumulative frequency plot

:::{.callout-warning}
Before we do anything - make sure to have downloaded the dataset for this computer session by clicking [**[HERE]**](https://github.com/UCLPG-MSC-SGDS/GEOG0186/raw/main/datasets/Dataset%20for%20Week%203.zip). It contains the file `Barcelona_Air_Pollution_data.csv` - this comma separated values (CSV) file contains the data needed to follow today's tutorial.

**Instructions**
In your computer, do the following:

1. Create a new folder on your desktop and rename the folder **GEOG0186**
2. Next, create a new sub-folder within **GEOG0186** and rename it as **Week 3**.
3. From the downloaded folder **Dataset for Week 3**, make sure to unzip and transfer **ALL** the datasets directly to the **Week 3** folder.
:::

## Short Lecture Videos [OPTIONAL]

Jump straight to the coding exercise by clicking [**HERE**](https://uclpg-msc-sgds.github.io/GEOG0186/04-frequency_distribution.html#analysing-air-pollution-data-in-barcelona) if you want to skip this section!

### What is Statistics?

**Definition 1**: Statistics is a branch in the mathematical sciences that pertains to the collection, analysis, interpretation, and graphical presentation of data. The best thing about statistics is that it’s a highly applied branch of science which is applicable to many areas such as social science, politics, health (e.g., epidemiology), business & finance, environmental sciences and geography. 

Statistics is broadly split into two main areas:

1.	Descriptive statistics, which focuses on describing the visible characteristics about a dataset
2.	Inferential statistics is more research-based, which focuses on making predictions (rather than stating facts) and testing hypothesis about a phenomenon.

**Definition 2**: A variable is any characteristics, numbered value, or quantity that can be measured or counted. A variable can also be referred to a data Item. A variable can be broadly classified as discrete, continuous or categorical variable.

We have provided two videos: the first which broadly explains why statistics as a subject is important; and the second explains in much details what statistics is as a subject, and what are the various data types.

**[Theory] Why is statistics important? (Length: 13:21 minutes)**
```{r video_6, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('BTQihTqIR8Y', height = 400) %>% use_align('center')
```
Watch on YouTube [[**LINK**]](https://youtu.be/BTQihTqIR8Y)

**[Theory] What is statistics, and the types of variables? (Length: 31:17 minutes)**
```{r video_7, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('FJh6Cu-ATLM', height = 400) %>% use_align('center')
```
Watch on YouTube [[**LINK**]](https://youtu.be/FJh6Cu-ATLM)

## Analysing air pollution data in Barcelona

We will focus on descriptive statistics as an introduction introducing everyone to the absolute basics. Descriptive statistics is all about knowing the **data types** and finding the **distribution**, **central tendency** and **variability** in such data set. These four key words may sound intimidating – but trust me – it is very easy! Let us learn how to perform the following aspect of finding the distribution in RStudio using the air pollution data for Barcelona.

### Setting Working Directory & Reading a CSV File (Length: 00:13:54)

```{r, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('unkwigmi2xY', height=400, allowfullscreen = TRUE) %>% use_align('center')
```
[[**Watch on YouTube**]](https://youtu.be/unkwigmi2xY)

Let us import for following dataset `Barcelona_Air_Pollution_data.csv` into RStudio, and call this object `air_ quality_data`.

```{r set_up_path_GIF2, include = FALSE}
knitr::opts_knit$set(root.dir = "/Users/anwarmusah/Documents/Websites/GEOG0186/datasets/All Data")
knitr::opts_chunk$set(cache = FALSE)
```

Remember - always make sure that your work directory is linked to your folder containing your data.

For **Windows**:

```{r, eval=FALSE}
setwd("C:/Users/accountName/Desktop/GEOG0186/Week 3")
```

For **Macs**:

```{r, eval=FALSE}
setwd("/Users/accountName/Desktop/GEOG0186/Week 3")
```

Now, import you the data set as follows:

```{r import_dataset}
air_quality_data <- read.csv("Barcelona_Air_Pollution_data.csv")
```

You use the command `View()` see the full data viewer, or `head()` to see the first five rows of the dataset. 

```{r, eval=FALSE}
# see imported dataset
View(air_quality_data)
```

```{r, eval=FALSE}
head(air_quality_data)
```

You will notice that the data contains six variables with the following information:

**Variable name**|**Variable Type**|**Information**
---------------- | ----------------- | ----------------------------------------
`Location`| String/Text only | Name of location Eixample, Barcelona
`ReadingDate`| Date | Data collection date for air quality measures
`NO2_est` | Continuous | Measurements for Nitrogen dioxide (NO$_2$) (ppb)
`NO2_category` | Categorical | Health impacts (negligible/low/moderate/high)
`PM10_est` | Continuous | Measurements for Particulate matter (PM$_10$)
`PM10_category` | Categorical | Health impacts (negligible/low/moderate)

:::{.callout-important}
The `NO2_est`, for example, contains measurable items i.e., 718 observations for concentrations of ambient NO$_2$ in Eixample area of Barcelona, and hence its a continuous variable. These estimates have been categorised in accordance with their health dangers i.e., negligible ($<$ 10 ppb); low (11-50 ppb);
:::

Let us begin to analyse `NO2_est` and `NO2_category` with **Frequency Distributions**

## Frequency Distributions

### Using the `cut()`, `seq()` & `table()` functions (Length: 00:17:56)

```{r, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('HzlL_PVdy6A', height=400, allowfullscreen = TRUE) %>% use_align('center')
```
[[**Watch on YouTube**]](https://youtu.be/HzlL_PVdy6A)

We use frequency distribution to analyse a set of continuous measurements. In data handling in this context, there are two outputs generated: 

1. **Frequency**, which tells us how often a particular result was obtained. From this we can calculate a percentage value which is referred to as **Relative Frequency**.  
2. **Cumulative Frequency**, this is a cumulative sum of the frequencies, which indicates how often a result was obtained that is less than a stated value in our collection of data. Again, from this we can also calculate a cumulative percentage value which is referred to as **Cumulative Relative Frequency**.

Suppose, we want to assess the 718 observations for air pollutant Nitrogen Dioxide (NO$_2$).

Let's list the observations for Nitrogen Dioxide (NO$_2$) in Barcelona:

```{r no2_list}
air_quality_data$NO2_est
```

In a list format it is quite difficult to make head or tail on what observations appear frequently and its distribution. To summarise this - it will be helpful to classify the information into **Classes** and then obtain the **Frequency** and **Cumulative Frequency** in a table. We call this table a **Frequency Table**.

The minimum value for NO$_2$ is 2 and the maximum is 130. We can group the 718 observations into 13 **classes** using an interval of 10s e.g., `1-10, 11-20, 21-30, 31-40, 41-50, 51-60, 61-70, 71-80, 81-90, 91-100, 101-110, 111-120` and `121-130`

:::{.callout-important}
The way and manner you specify the classes and interval are up to you really. Here, 10 is being used for convenience.
:::

The interval width is 10, we can generate sequence of number from 0 to 130, inclusively, to create the **classes** which in turn be used to group the 718 observations into 13 classes using the `seq()` and `cut()`.

For example:

```{r gen_seq}
# using starting value as 0
# using highest value as 130
# using interval as 10

#  specify in this order the lower, highest, interval value in seq() function
classes <- seq(0, 130, 10)
classes
```

The sequence of values are stored in the object called `classes`. Now, let us apply the `cut()` function to group the NO$_2$ data accordingly. We can do this by generating a new variable called `Groups`.

```{r gen_classes}
# tell the cut() function to group NO2_est using the classes object
air_quality_data$Groups <- cut(air_quality_data$NO2_est, breaks=classes)
air_quality_data$Groups
```

The observations have now been grouped to the classes. You can see this explicitly in the data viewer:

```{r, eval=FALSE}
View(air_quality_data)
```

:::{.callout-important}
**What have we done here?** The first value under the `NO2_est` column is **61**, this value falls between **61-70** and hence under the `Group` column is was classed into the `(60,70]` interval by the `cut()` function. The second value in `NO2_est` is **59**, and hence it was classed into the `(50,60]` interval, and so on. Note that the interval `(60, 70]` is the equivalent of saying: **"any numbers greater than `60` (i.e., from `60.01` onwards but excluding `60` from that interval), and at the same time being less than or equal to `70`, inclusively"**. The round bracket `(` represents any number greater than `60`, whilst the square bracket `]` closes the interval translating to any number being less than or equal `70` at the same time.  
:::

### Computing the Frequency Distribution Table (Length: 00:27:53)

```{r, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('YPoGo74MWTY', height=400, allowfullscreen = TRUE) %>% use_align('center')
```
[[**Watch on YouTube**]](https://youtu.be/YPoGo74MWTY)

We can now generate our **Frequency Table** and hence determine **Frequency** and **Cumulative Frequency** of the ambient levels of NO$_2$ in Eixample. We perform by using the `table()` function to tabulate the frequency of values that were grouped within an interval using the `Group` column. 

```{r table_freq}
table(air_quality_data$Groups)
```

Using `table()` function only shows results in the Console - lets store the table results in a **data frame** object and call it `frequency_results`:

```{r table_freq_result1}
frequency_results <- data.frame(table(air_quality_data$Groups))
frequency_results
```

You can see column names `Var1` and `Freq`. The `Var1` is the original `Groups` columns which incidentally been renamed to `Var1`. The `Freq` column was generated from the `table()` function. We can rename the 1st and 2nd columns using `colnames()`.

```{r column_name1}
# rename first column t9 "Groups"
# rename second column to "Frequency"
# print new variable names in console using names() function

colnames(frequency_results)[1] <- "Groups"    
colnames(frequency_results)[2] <- "Frequency" 
names(frequency_results) 
frequency_results
```

Finally, we derive the **Relative Frequency** i.e., a percentage that is derived by dividing each frequency value from a group by the total number of observations (i.e., in this case: 718). We can add the `relativeFreq` column to the `frequency_results` table.

```{r relative_freq}
# generate a new column
frequency_results$relativeFreq <- frequency_results$Frequency/718
```

:::{.callout-note}
**Interpretation of frequency**: The above table output show the frequency distribution of a set of concentrations for Nitrogen Dioxide measured in Eixample (in Barcelona). The group with the highest frequency value is `50-60ppb` (i.e., 137) which accounts for **0.1908 (19.08%)** of the data. These measurements typically fall under the category that's considered to cause moderate harm to humans.   
:::

Let's add the **Cumulative Frequency** and **Cumulative Relative Frequency** i.e., percentage using this cumulative summation code i.e., `cumsum` function below:

```{r cumulative_values}
# add cumulativeFreq column to the data frame by adding Frequency using cumsum() function
frequency_results$cumulativeFreq <- cumsum(frequency_results$Frequency)

# add cumulativeRelFreq column to the data frame by adding Frequency using cumsum() function
frequency_results$cumulativeRelFreq <- cumsum(frequency_results$relativeFreq)

# print table results
frequency_results
```

:::{.callout-warning}
**Thoughts to self**: `cumsum` function... like WTF man?! 
:::

:::{.callout-note}
**Interpretation of cumulative frequency**: The above table output show the cumulative frequency distribution ambient concentrations for Nitrogen Dioxide measured in Eixample (in Barcelona). We can see that there are  246 measurements or less with N0$_2$ concentrations to be considered as negligible or low impact to health (`<50ppb`). This corresponds to **0.3426 (34.26%)** of the data. 

Conversely, we can also say - we can see that there are 472 measurements with N0$_2$ concentrations more than `50ppb` which is considered to be moderate or high impact to human health. This corresponds to **0.6573 (65.73%)** of the data. 
:::

### Graphical Representation of Frequency Data (Length: 00:23:59)

```{r, warnings=FALSE, message=FALSE, echo=FALSE}
library(vembedr)
embed_youtube('QifkfNmmcSA', height=400, allowfullscreen = TRUE) %>% use_align('center')
```
[[**Watch on YouTube**]](https://youtu.be/QifkfNmmcSA)

The frequency table for **Frequencies** and **Cumulative Frequencies** can be graphical represented in a form of **Histogram** and **Cumulative Frequency Plot** (or **Ogive Plot**) respectively. Now, the data we need must be in its original form (i.e., not grouped) to plot the histogram, and we will need to use the `classes` object which we created earlier on from the `seq()` function so as to be used as `breaks` in the `hist()` plot function:

```{r histogramPlot}
hist(air_quality_data$NO2_est, breaks = classes)
```

The above graph is not to the expected standards! It is missing key details such as the title and label for the x-axis. Let's apply some cosmetics such as a main title and label for the x-axis

```{r histogram_cosmetics}
hist(air_quality_data$NO2_est, breaks = classes, main = "Histogram for NO2 in Barcelona", xlab = "NO2 estimates (ppb)")
```

:::{.callout-note}
**Interpretation of histogram**: The above figure output describes the shape for ambient measures of NO$_2$ in Barcelona which appears bell-shaped centered around 60ppb. Note that the frequency bars in this graph are essentially the same as the frequency values in the table.
:::

Lastly, we then compute its cumulative frequency with the `cumsum()` function to support the interpretation. The coding needs a bit of hacking because we need to force a starting zero element for this graph to work.

```{r cumsum_plot}
cumulfreq0 <- c(0, cumsum(frequency_results$Frequency))
plot(classes, cumulfreq0)
```

Apply the appropriate cosmetics to output by adding the following:

- Main title
- Axis titles for x- and y-axis
- Connecting the points to form a full cumulative frequency/ogive plot

```{r cumsum_cosmetics}
cumulfreq0 <- c(0, cumsum(frequency_results$Frequency))
plot(classes, cumulfreq0, main="Cumulative Frequency for N02 in Barcelona", xlab="NO2 estimates (ppb)", ylab="Cumulative Frequencies")
lines(classes, cumulfreq0) 
```

## Exercise

1. Generate a **Frequency Distribution Table** for the PM$_10$ variable in the `air_quality_data` data frame object. It should contain the following:

- Frequency
- Relative Frequency
- Cumulative Frequency
- Cumulative Relative Frequency

:::{.callout-note}
**HINTS** to consider: 

- Use the `min()` and `max()` functions to know the minimum and maximum values for PM$_10$ in the dataset.
- Use the sequence function i.e., `seq()` to generate a sequence of numbers to be made classes for grouping the PM$_10$ values. Consider using the interval of **5** in your generating the sequence of numbers.
- Use the `cut` accordingly to create the groups
- Use both the `table()` and `data.frame()` functions accordingly to generate the desired outputs
- For the cumulative estimates - use the `cumsum()` function
:::

2. What would the appropriate interpretation be for the relative frequency for highest PM$_10$ group measured in Barcelona?

3. Generate a histogram plot using `hist()` function that is fully annotated with title and x- and y-titles.

:::{callout-important}
Have a go at these questions before revealing the solution codes and output below
:::

<details><summary>**Click here to see solution code:**</summary>

```{r solutions}
# Solutions for 1
# Using PM10
min(air_quality_data$PM10_est)
max(air_quality_data$PM10_est)
# create classes
classes_PM10 <- seq(0, 60, 5)
air_quality_data$Groups_PM10 <- cut(air_quality_data$PM10_est, breaks = classes_PM10)
table(air_quality_data$Groups_PM10)
# Generating Frequency Tables
frequency_table_PM10 <- data.frame(table(air_quality_data$Groups_PM10))
# renaming columns
colnames(frequency_table_PM10)[1] <- "Groups"
colnames(frequency_table_PM10)[2] <- "Frequency"
# Calculation of relative frequency (proportion)
frequency_table_PM10$relativeFreq <- frequency_table_PM10$Frequency/718
# Calculation of cumulative frequency and cumulative relative frequency (proportion)
frequency_table_PM10$cumulativeFreq <- cumsum(frequency_table_PM10$Frequency)
frequency_table_PM10$cumulativeRelFreq <- cumsum(frequency_table_PM10$relativeFreq)
# show table
head(frequency_table_PM10, 12)

# Solutions for 2
# For PM10, the group with the highest frequency value is `25-30μm` (i.e., 143) which accounts for 0.1991
# (19.91%) of the data.

# Solutions for 3
# histogram plot
hist(air_quality_data$PM10_est, 
	breaks = classes_PM10, main = "Histogram: PM10 in Barcelona", 
	xlab = "PM10 estimates [μm]")
```
</details>